for each item here, identify if it's a bug or a new feature. if it's a new feature, assess whether it's large and has multiple open questions about it.  if it is large, follow the @thinking/from-thinking-to-coding/ methodology to understand the feature and implement it in phases.

add pointers to specs, implementation plans and any other documentation if any are created for any of the items.

update the status of each of the items below.  mrak them as "in progress" once you start working on it.  mark it as "implemented" when it has been impelemented in code, but not yet confirmed to be fully working.

when it's fully working, move it to a todo-done.md file

# in the meetings page for attendees, the system should detect the people in the call.  if there's a new person detected, add that person in this section.  

# auto meeting title generation
  - Type: new feature
  - Size: medium
  - Status: in progress
  - Docs: docs/specs/auto-meeting-title-spec.md, docs/plans/auto-meeting-title-plan.md

the meeting title should be automatically generated by the content unless the user manually sets it.   it should be generated sometime early in the meeting as a draft.  then when the meeting is completed and the summarization has happened, it should be updated with a more final one.  but if the user manually sets the title at any point, that should be kept

# smart real time summary parsing
  - Type: new feature
  - Size: large (multi-step, open questions: data model, prompts, UI, storage)
  - Status: in progress
  - Docs: docs/specs/smart-real-time-summary-spec.md, docs/plans/smart-real-time-summary-plan.md

every 30 seconds, we should prompt the llm to summarize the conversation so far.  usually a conversation will have multiple points of discussioin that flow from one to another.   to make the summary parsing stable notetaker should keep track of a what is "summarized" and what is "in progresss".   "in progress" is the current topic being discussed, and who's summary is still evolving.  

in any live conversation, there should be 3 categories of transcribed text that notetaker manages.  1) done.  2) draft.  3) streaming.   there should also be 2 categories of summarized text that the notetaker manages: 1) summarized, 2) interim.

here's the workflow:

1) all new live transcriptions should get added to "streaming".  
2) every 30 seconds,  notetaker should take as much content from "streaming" as possible starting from the top and going as far down as posible, but only whole sentences.  do not cut off sentences.  
3) since this is a live transcription, it will have some errors.  it should first send it to the llm with a well crafted prompt that explains how transcriptions have errors, and the typical type of errors that voice transcriptions have.  it should process the transcribed text and use the context of the conversation available for it to clean up the transcription and try to make it more likely to be correct to what the people actually said. 
4) it should then append it to the previously transcribed text in "draft".
5) it should pass the draft to the llm and ask the llm to identify the number of different topics that are discussed in the draft.  it should create a summary of each of the topics it identified.  starting from the first topic, if that topic has been fully discussed, it should append the summarization of that topic to the "summarized" cateogry and remove it from "interim". it should append the corresponding transcript to the "done" category and remove it from "draft".  
6) do this for each topic in draft except the last topic of draft which is still being discussed.  

# smart real time summary debug ui.
  - Type: new feature
  - Size: small
  - Status: in progress
  - Docs: docs/specs/smart-real-time-summary-spec.md, docs/plans/smart-real-time-summary-plan.md

in the meeting ui, add a debug button at the bottom.  when the user presses the debug button, show two columns of text boxes that show all of these content streams as they are being updated so that we can debug it. on the left have the "done" "draft" and "streaming" text.   on the right hav ethe "summarized" and "interim" content.  these should be consistently updating to the current contents. 

these should constantly be scrolled to the bottom.


* user login
  - Type: new feature
  - Size: large (multi-step, open questions: auth provider, scopes, privacy, multi-user storage layout)
  - Status: deferred
  - Docs: docs/specs/user-login-spec.md, docs/plans/user-login-plan.md

create a user login.  can we connect this to google identiy login?  let the user profile be connected to google and also get access to the user's google drive?

change the file storage to be structured for multiple users and load the meeting configurations and the settings to be per user.  make it so that each person's login get their own meetings and settings

* cleanup main window
  - Type: new feature
  - Size: medium
  - Status: done
  - Docs: docs/specs/cleanup-main-window-spec.md, docs/plans/cleanup-main-window-plan.md

move the 3 transcript settings to the settings page

move the settings button to the upper right.  put it by a profile dropdown that lets the user login, logout and configure settings.

change the start and stop recording buttons to a single button that toggles recording and shows the current state of recording

have a meetings list that includes all the prior meetings in chronological order (most recent at the top).  if th4ere's one in progress it should be at the top and marked as "in progress"

move the delete, exprot to markdown, ability to change title and all the meeting specific changing controls into the meetings page.

on the meeting list, make a click on the meeting open the meeting page for the single meeting.


* meeting mode:
  - Type: new feature
  - Size: large (multi-step, open questions: live summary cadence, in-progress transcript refresh rules, meeting status definition)
  - Status: done
  - Docs: docs/specs/meeting-mode-spec.md, docs/plans/meeting-mode-plan.md

create a meeting view page.  this should be a dedicated web page - one per meeting.  this should be able to handle existing meetings in progress as well as meetings that have concluded.

on the left side there should be a meeting summary, which is an ai summary of the meeting.  if the meeting is in progress, it should create a running summary of the conversation. 

the right side should have the full trascript (or transcript in progress if the meeting is still going)

it should have all the meeting attendees at the top

* settings page
  - Type: new feature
  - Size: medium
  - Status: done
  - Docs: docs/specs/model-chooser-settings-spec.md

create a settings page that lets the user configure different necessary settings.  
move all of the settings that are currently in the main page into this settings page.

* ai model specification
  - Type: new feature
  - Size: large
  - Status: done
  - Docs: docs/specs/model-chooser-settings-spec.md

add the ability for users to set the api key or lm studio local server to know what ai model to use.  
enumerate all the available models.  let the user pick which model they want.  accept api keys from any of the frontier model providers.


* set live transcript as default "on"
  - Type: new feature
  - Size: small
  - Status: done
  - Docs: none

* for diarization, let's start with whisperx
  - Type: new feature
  - Size: large (new dependency + diarization pipeline swap)
  - Status: in progress
  - Docs: docs/specs/diarization-whisperx-spec.md, docs/plans/diarization-whisperx-plan.md
update the install script to properly install it.
implement the diarization to identify different speakers

* e2e test harness
  - Type: new feature
  - Size: medium
  - Status: implemented
  - Docs: docs/specs/e2e-test-harness-spec.md, docs/plans/e2e-test-harness-plan.md
end-to-end test harness for automated testing of in-progress features.
trigger via URL: /test?suite=<id> or /test?all=true
outputs detailed logs to logs/test_*.log