for each item here, identify if it's a bug or a new feature. if it's a new feature, assess whether it's large and has multiple open questions about it.  if it is large, follow the @thinking/from-thinking-to-coding/ methodology to understand the feature and implement it in phases.

add pointers to specs, implementation plans and any other documentation if any are created for any of the items.

update the status of each of the items below.  mrak them as "in progress" once you start working on it.  mark it as "implemented" when it has been impelemented in code, but not yet confirmed to be fully working.

when it's fully working, move it to a todo-done.md file

---

# user notes feature

purpose: we want to enable the user to type in notes and have it logged in time with the topic being discussed at that moment.  but we need to recognize that the note taken might come a bit later than the actual discussion due to natural lag.  

how this should work.

when the user starts writing a note, take a timestamp for when the user starts.  have a "submit" button with the notes.  when the user hits "submit" it should be added logged above the notes entry box.  keep a running log of all notes.   the user should be able to go back to any note and edit it.  this should not change the original timestamp.

the timestamp must be in the same format and basis as the transcript timestamp because we want the llm to know approximately what the note is referring to.

the notes field should also have an 'x' button taht clears the notes field.  if the user hits this and then starts a new note, there should be a new timestamp.

whenever the system summarizes the transcript, it should include these notes and the appropriate timestamp so that the llm knows what the user has said.  combine all of this to generate the summary.



---

# meeting ai query
  - Type: new feature
  - Size: medium
  - Status: implemented

provide an chat interface in the meeting page where the user can ask questions about a specific meeting.  the llm should answer questions primarily about that meeting, but it should also have access to all the other meetings to refer to if necessary as background context.  

load the context prompt for this in a separate file that i can see and edit

  Implementation notes:
  - Chat UI added to meeting page below Notes section
  - API: POST /api/chat/meeting/{meeting_id} (SSE streaming)
  - Prompt template: app/prompts/meeting_chat_prompt.txt
  - Supports optional include_related flag to search other meetings for context

# overall ai query
  - Type: new feature
  - Size: medium
  - Status: implemented

provide a chat interface in the main home page where the user can ask questions about the aggregate of all meetings.  the llm should be able to answer anything about all the meetings that have happened.  figure out what is the most efficient way for this to happen.   how can we enable this without necessarily sending the llm all the massive full transcripts of all meetings that have happened?

load the context prompt for this in a separate file that i can see and edit

  Implementation notes:
  - Chat UI added to home page after Meetings section
  - API: POST /api/chat/overall (SSE streaming)
  - Prompt template: app/prompts/overall_chat_prompt.txt
  - Uses hybrid search: keyword search on titles/summaries, load full transcripts for top 5 matches
  - SearchService (app/services/search_service.py) handles meeting search

---

# dark mode

implement a dark mode.  put the control in settings page that lets the user choose light, dark, or follow system.  
persist the setting to config.json

go through all pages and implement dark mode.  
check all icons to make sure the background and foreground of the icons follow the mode.


---

# Bug 3: No attendees detected (diarization not working)
  - Type: bug
  - Status: diagnosed
  - Plan: docs/plans/bug-fix-plan-2026-02-10.md#bug-3-no-attendees-detected-diarization-not-working

No attendees appearing in attendees list. Speakers are all null in transcript segments.

**Root cause:** HuggingFace pyannote model license not accepted. The model requires visiting https://hf.co/pyannote/speaker-diarization-3.1 and accepting terms.

**Evidence (from logs):**
```
Could not download 'pyannote/speaker-diarization-3.1' pipeline.
visit https://hf.co/pyannote/speaker-diarization-3.1 to accept the user conditions.
Diarization failed: WhisperX diarization failed
```

---

# update to attendee list
  - Type: new feature
  - Size: medium
  - Status: implemented

update the attendees ui to make it easier to identify and update the attendees.  the ui should show a list of each attendee.  when i select any person, there should be a text box on the right side that shows what the person has said so far to help me know who it is.

i should be able to rename the person selected.  give me a rename button that puts it in rename mode that does rename in place, similar to how file renames work.   

give me a button that does auto-rename.  this should prompt the ai to identify the name of the person based upon the conversation content.

  Implementation notes:
  - Replaced textarea with interactive attendee list (left column)
  - Selecting an attendee shows their spoken segments (right column)
  - Rename button enables inline editing (Enter to save, Escape to cancel)
  - Auto button calls AI to identify speaker name from their speech
  - Backend API: POST /api/meetings/{id}/attendees/{id}/auto-rename
  - Added `prompt()` method to all LLM providers for raw prompts

---

# auto-detect attendees
  - Type: new feature
  - Size: small
  - Status: pending

in the meetings page for attendees, the system should detect the people in the call.  if there's a new person detected, add that person in this section.  

---

# user login
  - Type: new feature
  - Size: large (multi-step, open questions: auth provider, scopes, privacy, multi-user storage layout)
  - Status: deferred
  - Docs: docs/specs/user-login-spec.md, docs/plans/user-login-plan.md

create a user login.  can we connect this to google identiy login?  let the user profile be connected to google and also get access to the user's google drive?

change the file storage to be structured for multiple users and load the meeting configurations and the settings to be per user.  make it so that each person's login get their own meetings and settings

---

# e2e test harness
  - Type: new feature
  - Size: medium
  - Status: implemented
  - Docs: docs/specs/e2e-test-harness-spec.md, docs/plans/e2e-test-harness-plan.md

end-to-end test harness for automated testing of in-progress features.
trigger via URL: /test?suite=<id> or /test?all=true
outputs detailed logs to logs/test_*.log
