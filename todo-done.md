# Completed Features

Items moved here from todo when fully working.

---

## auto meeting title generation
  - Type: new feature
  - Size: medium
  - Status: done
  - Docs: docs/specs/auto-meeting-title-spec.md, docs/plans/auto-meeting-title-plan.md

the meeting title should be automatically generated by the content unless the user manually sets it.   it should be generated sometime early in the meeting as a draft.  then when the meeting is completed and the summarization has happened, it should be updated with a more final one.  but if the user manually sets the title at any point, that should be kept

---

## smart real time summary parsing
  - Type: new feature
  - Size: large (multi-step, open questions: data model, prompts, UI, storage)
  - Status: done
  - Docs: docs/specs/smart-real-time-summary-spec.md, docs/plans/smart-real-time-summary-plan.md

every 30 seconds, we should prompt the llm to summarize the conversation so far.  usually a conversation will have multiple points of discussioin that flow from one to another.   to make the summary parsing stable notetaker should keep track of a what is "summarized" and what is "in progresss".   "in progress" is the current topic being discussed, and who's summary is still evolving.  

in any live conversation, there should be 3 categories of transcribed text that notetaker manages.  1) done.  2) draft.  3) streaming.   there should also be 2 categories of summarized text that the notetaker manages: 1) summarized, 2) interim.

here's the workflow:

1) all new live transcriptions should get added to "streaming".  
2) every 30 seconds,  notetaker should take as much content from "streaming" as possible starting from the top and going as far down as posible, but only whole sentences.  do not cut off sentences.  
3) since this is a live transcription, it will have some errors.  it should first send it to the llm with a well crafted prompt that explains how transcriptions have errors, and the typical type of errors that voice transcriptions have.  it should process the transcribed text and use the context of the conversation available for it to clean up the transcription and try to make it more likely to be correct to what the people actually said. 
4) it should then append it to the previously transcribed text in "draft".
5) it should pass the draft to the llm and ask the llm to identify the number of different topics that are discussed in the draft.  it should create a summary of each of the topics it identified.  starting from the first topic, if that topic has been fully discussed, it should append the summarization of that topic to the "summarized" cateogry and remove it from "interim". it should append the corresponding transcript to the "done" category and remove it from "draft".  
6) do this for each topic in draft except the last topic of draft which is still being discussed.  

---

## smart real time summary debug ui
  - Type: new feature
  - Size: small
  - Status: done
  - Docs: docs/specs/smart-real-time-summary-spec.md, docs/plans/smart-real-time-summary-plan.md

in the meeting ui, add a debug button at the bottom.  when the user presses the debug button, show two columns of text boxes that show all of these content streams as they are being updated so that we can debug it. on the left have the "done" "draft" and "streaming" text.   on the right hav ethe "summarized" and "interim" content.  these should be consistently updating to the current contents. 

these should constantly be scrolled to the bottom.

---

## cleanup main window
  - Type: new feature
  - Size: medium
  - Status: done
  - Docs: docs/specs/cleanup-main-window-spec.md, docs/plans/cleanup-main-window-plan.md

move the 3 transcript settings to the settings page

move the settings button to the upper right.  put it by a profile dropdown that lets the user login, logout and configure settings.

change the start and stop recording buttons to a single button that toggles recording and shows the current state of recording

have a meetings list that includes all the prior meetings in chronological order (most recent at the top).  if th4ere's one in progress it should be at the top and marked as "in progress"

move the delete, exprot to markdown, ability to change title and all the meeting specific changing controls into the meetings page.

on the meeting list, make a click on the meeting open the meeting page for the single meeting.

---

## meeting mode
  - Type: new feature
  - Size: large (multi-step, open questions: live summary cadence, in-progress transcript refresh rules, meeting status definition)
  - Status: done
  - Docs: docs/specs/meeting-mode-spec.md, docs/plans/meeting-mode-plan.md

create a meeting view page.  this should be a dedicated web page - one per meeting.  this should be able to handle existing meetings in progress as well as meetings that have concluded.

on the left side there should be a meeting summary, which is an ai summary of the meeting.  if the meeting is in progress, it should create a running summary of the conversation. 

the right side should have the full trascript (or transcript in progress if the meeting is still going)

it should have all the meeting attendees at the top

---

## settings page
  - Type: new feature
  - Size: medium
  - Status: done
  - Docs: docs/specs/model-chooser-settings-spec.md

create a settings page that lets the user configure different necessary settings.  
move all of the settings that are currently in the main page into this settings page.

---

## ai model specification
  - Type: new feature
  - Size: large
  - Status: done
  - Docs: docs/specs/model-chooser-settings-spec.md

add the ability for users to set the api key or lm studio local server to know what ai model to use.  
enumerate all the available models.  let the user pick which model they want.  accept api keys from any of the frontier model providers.

---

## set live transcript as default "on"
  - Type: new feature
  - Size: small
  - Status: done
  - Docs: none

---

## diarization with whisperx
  - Type: new feature
  - Size: large (new dependency + diarization pipeline swap)
  - Status: done
  - Docs: docs/specs/diarization-whisperx-spec.md, docs/plans/diarization-whisperx-plan.md

update the install script to properly install it.
implement the diarization to identify different speakers

Implementation notes:
- WhisperX and pyannote providers implemented for batch/file diarization
- Diart provider added for real-time diarization during live recording
- Unified TranscriptionPipeline centralizes segment formatting, diarization, summarization
- All transcription flows (file, streaming, simulated, live) now share common pipeline
- Real-time diarization activates when provider=diart is configured
- Requires accepting HuggingFace licenses for pyannote models

Commits:
- f2b4c02: Fix diarization in simulated transcription, improve HF error messages
- ab0a105: Unify transcription code flows with TranscriptionPipeline
- 4b70efa: Add real-time speaker diarization with Diart
